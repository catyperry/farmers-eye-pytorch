{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86821e0f",
   "metadata": {},
   "source": [
    "# 3070 running hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae84b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ca71f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3070'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if cuda is available and running on the right gpu\n",
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fedd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test_data_balanced.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa383eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1babdd9d",
   "metadata": {},
   "source": [
    "Preprocess the images for training, so that the Image Transformation does not have to be done for each training attempt.\n",
    "The Transformation is pretty CPU and Disk I/O heavy.\n",
    "Loading the preprocessed tensors eliminates that load. Also the tensors are kept in VRAM for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8d93cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run preprocess_transform.py --data_dir ./inputs/training --output_dir ./inputs/transformed_training\n",
    "#%run preprocess_transform.py --data_dir ./inputs/test_balanced --output_dir ./inputs/transformed_test_balanced\n",
    "\n",
    "%run preprocess_transform.py --dataset train\n",
    "%run preprocess_transform.py --dataset test_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5375c0d3",
   "metadata": {},
   "source": [
    "good batch_sizes would be denominators of 4800\n",
    "100 92% GPU, 2.1G VRAM, 5s\n",
    "200 90% GPU, 2.4G VRAM, 5s\n",
    "300 93% GPU, 3.1G VRAM, 4s\n",
    "400 93% GPU, 3.4G VRAM, 4s\n",
    "600 93% GPU, 4.7G VRAM, 4s\n",
    "800 93% GPU, 6.0G VRAM, 4s\n",
    "1200 93% GPU, 7.7G VRAM, 5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed5bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from train import main as main_train\n",
    "\n",
    "main_train(\n",
    "    model_name='mobilenet_v2',\n",
    "    data_dir_train='inputs/data_train_local',        # Before was \"transformed_training\" \n",
    "    data_dir_test='inputs/data_test_local',\n",
    "    output_model_dir='outputs',\n",
    "    batch_size=200,\n",
    "    num_epochs=1,\n",
    "    learning_rate=0.0035148759,\n",
    "    resume=False,\n",
    "    test=True\n",
    ")\n",
    "\n",
    "# %run train.py \\\n",
    "#     --data_dir_train inputs/transformed_training \\\n",
    "#     --batch_size 200 \\\n",
    "#     --num_epoch 10 \\\n",
    "#     --test True \\\n",
    "#     --data_dir_test ./inputs/transformed_test_balanced \\\n",
    "#     --output_model_dir ./outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243781ce",
   "metadata": {},
   "source": [
    "Run this in Terminal\n",
    "\n",
    "```sh\n",
    "uv run train.py\n",
    "    --data_dir_train inputs/transformed_training\n",
    "    --batch_size 200\n",
    "    --num_epoch 3000\n",
    "    --test True\n",
    "    --data_dir_test inputs/transformed_test_balanced\n",
    "    --output_model_dir outputs\n",
    "```\n",
    "\n",
    "`uv run tensorboard --logdir=runs`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f0c6ad",
   "metadata": {},
   "source": [
    "# Running Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c46465d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model: vit_base_patch16_224\n",
      "Hyperparameters: {'learning_rate': 0.0001, 'batch_size': 1000, 'num_epochs': 1, 'test_every_x_epochs': 3, 'weight_decay': 0.01}\n",
      "Train Dataset: Found 4800 images, 12 classes: ['B11', 'B12', 'B13', 'B14', 'B15', 'B16', 'B21', 'B22', 'B31', 'B32', 'B33', 'B55']\n",
      "Test Dataset: Found 1020 images, 12 classes: ['B11', 'B12', 'B13', 'B14', 'B15', 'B16', 'B21', 'B22', 'B31', 'B32', 'B33', 'B55']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Farmer\\Desktop\\FarmersEye\\farmers-eye-pytorch\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using optimizer: AdamW (Adam with weight decay 0.01)\n",
      "Moving model to cuda\n",
      "Compiling model\n",
      "\n",
      "Starting training from epoch 1 to 1\n",
      "Logging to TensorBoard directory: ./runs\\vit_base_patch16_224_20250708_204341\n",
      "Run 'tensorboard --logdir=runs' to view training progress\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 2/2 [00:08<00:00,  4.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Test Loss: 2.7470, Test Acc: 0.1069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 5it [00:16,  3.21s/it]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Train Loss: 2.6549, Train Acc: 0.1215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 2/2 [00:01<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Loss: 2.5315, Test Acc: 0.1343 (Best: 0.1343)\n",
      "Model saved to outputs_vit\\000001_model.pth\n",
      "\n",
      "Training completed!\n",
      "TensorBoard logs saved to: ./runs\\vit_base_patch16_224_20250708_204341\n",
      "View with: tensorboard --logdir=./runs\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from train import main as main_train\n",
    "\n",
    "learning_rates = [0.01, 0.005, 0.001, 0.0001]\n",
    "#opt = ['sgd', 'adam', 'adamw']\n",
    "#batch = [1000]\n",
    "for item in learning_rates:\n",
    "    main_train(\n",
    "        model_name='vit_base_patch16_224',\n",
    "        data_dir_train='inputs/data_train_local',\n",
    "        data_dir_test='inputs/data_test_local',\n",
    "        output_model_dir='outputs_vit/model_output',\n",
    "        num_epochs = 1000, \n",
    "        learning_rate=item,\n",
    "        batch_size=512, \n",
    "        test_every_x_epochs=3,\n",
    "        resume=False,\n",
    "        test=True, \n",
    "        metric=True, \n",
    "        optimizer_type= 'sgd', \n",
    "        momentum=0.0,\n",
    "        weight_decay=0.01  \n",
    " )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820107c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from train import main as main_train\n",
    "\n",
    "main_train(\n",
    "    model_name='vit_huge_patch14_224',\n",
    "    data_dir_train='inputs/transformed_training', \n",
    "    data_dir_test='inputs/transformed_test_balanced',\n",
    "    output_model_dir='outputs_vit',\n",
    "    resume=False,\n",
    "    test=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978127d2",
   "metadata": {},
   "source": [
    "```sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10110254",
   "metadata": {},
   "source": [
    "# Foundation Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
